---
# ------------------------------------------------------------------------------
# General cluster settings
# ------------------------------------------------------------------------------
hdfs_cluster_name: tsdb
hdfs_user: hdfs
hdfs_group: hadoop
hdfs_user_home: "/var/lib/hadoop-hdfs"
hdfs_conf_dir: "/etc/hadoop/conf"

# Directories where journal nodes should store edits
hdfs_dfs_journalnode_edits_dir: "/tmp/dfs/journaldir"
hdfs_dfs_journalnode_edits_dir_perm: "700"

# Bootstraps the cluster ( Format namenodes, zkfc, journalnodes, start all services)
# Please read the code before you activate this option.
# Especially if you already have a hadoop setup in place.
hdfs_bootstrap: True

# Redistribute ssh keys every time?
hdfs_redistribute_ssh_keys: True

hdfs_parent_dir: /usr/local  # hadoop binaries will be copied here
hdfs_ssh_known_hosts_file: "{{ hdfs_user_home }}/.ssh/known_hosts"

# ------------------------------------------------------------------------------
# Hadoop host variables
# ------------------------------------------------------------------------------
hdfs_namenodes: "{{ groups.hdfs_namenodes }}"
hdfs_hadoop_hosts: "{{ groups.all }}"
hdfs_journalnodes: "{{ groups.master }}"
hdfs_datanodes: "{{ groups.data }}"
hdfs_zookeeper_hosts: "{{ groups.master }}"

hdfs_log_dir: /var/log/hadoop
hdfs_tmpdir: "/tmp"

# ------------------------------------------------------------------------------
# Hadoop configuration
# ------------------------------------------------------------------------------

# Symlink for hadoop to the version you are installing
hdfs_bin_dir: "/bin"

# Directories where namenode should store metadata
hdfs_namenode_dir_list:
 - "/data/dfs/name"
# Directories where secondary namenode should store temporary images to merge
hdfs_namenode_checkpoint_dir_list:
 - "/data/dfs/secondaryname"
# Directories where datanodes should store data
hdfs_datanode_dir_list:
 - "/data/dfs/data"

hdfs_enable_short_circuit_reads: true  # IMPORTANT: this property should be 'true' or 'false'

# ------------------------------------------------------------------------------
# Extended core-site.xml
# ------------------------------------------------------------------------------
hdfs_tmpdir_user: "{{hdfs_tmpdir}}/hadoop-${user.name}"
hdfs_fs_trash_interval: 0
hdfs_fs_trash_checkpoint_interval: 0  # If 0 this is set to the value of hdfs_fs_trash_interval by hadoop_log_maxfilesize

# ------------------------------------------------------------------------------
# Extended hdfs-site.xml
# ------------------------------------------------------------------------------

hdfs_fs_permissions_umask_mode: "002"
hdfs_dfs_permissions_superusergroup: "{{hdfs_group}}"
hdfs_dfs_blocksize: 134217728
hdfs_dfs_namenode_write_stale_datanode_ratio: "0.5f"
hdfs_dfs_datanode_du_reserved: "1073741824"
hdfs_dfs_datanode_data_dir_perm: "700"
hdfs_dfs_datanode_max_transfer_threads: 4096
hdfs_dfs_replication: 2
hdfs_dfs_replication_max: 50
hdfs_dfs_namenode_replication_min: 1
hdfs_dfs_namenode_checkpoint_period: 3600
# the recommended 'namenode handler count' is best defined by formula: lb(#datanodes) * 20
# and recommended 'service handler count'  50% of the previous value
# Ref: https://community.hortonworks.com/articles/43839/scaling-the-hdfs-namenode-part-2.html
# -> for an average cluster 10-20 DNs the value 64 is a good average (for 32+ DNs -> 100+)
hdfs_dfs_namenode_handler_count: 32
hdfs_dfs_namenode_service_handler_count: "{{ (hdfs_dfs_namenode_handler_count / 2)|int }}"
hdfs_dfs_namenode_avoid_read_stale_datanode: true
hdfs_dfs_namenode_avoid_write_stale_datanode: true
hdfs_dfs_namenode_audit_log_async: false
hdfs_dfs_client_file_block_storage_locations_num_threads: 10
hdfs_dfs_client_file_block_storage_locations_timeout_millis: 1000
hdfs_dfs_domain_socket_path_folder: /var/lib/hadoop-hdfs

# ------------------------------------------------------------------------------
# log4j.properties vars
# ------------------------------------------------------------------------------

hadoop_log_maxfilesize: "256MB"
hadoop_log_maxbackupindex: 20

# ------------------------------------------------------------------------------
# HA specific setup
# ------------------------------------------------------------------------------
# Use ssh as fencing method (other option is shell(/bin/true)
hdfs_ssh_fence: False

hdfs_ha_enabled: "{{hdfs_namenodes | count > 1}}"
hdfs_default_fs: "hdfs://{{ hdfs_nameservices if hdfs_ha_enabled else hdfs_namenodes[0] + ':8020' }}"
hdfs_nameservices: "{{ hdfs_cluster_name }}"
hdfs_zookeeper_client_port: 2181
hdfs_zookeeper_quorum: "{{ hdfs_zookeeper_hosts | join(':' + (hdfs_zookeeper_client_port | string) + ',')  }}:{{ hdfs_zookeeper_client_port | string }}"

#hdfs_rack_script_awk: '"{if ($4 < 3) print "/default/rack-1"; else print "/default/rack-2" }"'
hdfs_rack_script_path: "{{hdfs_conf_dir}}/rack-awareness.sh"
